[["index.html", "STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 5 1.1 Support vector machines", " STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 5 In week 5, we have studied support vector machines (SVMs) and more specifically, maximal margin classifier (hard-margin SVM with linear kernel), support vector classifier (soft-margin SVM with linear kernel) and nonlinear/kernelised SVM. 1.1 Support vector machines Before applying SVM, we need to take two important practical considerations into account. First, SVM, by design, is only applicable to binary-class classification problem. For multi-class problem, conversion to binary-class is essential by using either one versus one approach or one versus all approach. Secondly, SVM is not scale-invariant and therefore it is important to standardise the data as a pre-processing step. SVM can be fitted by using the svm command from e1071 package. An example is as follows. Model &lt;- svm(Y~., data, type=&quot;C-classification&quot;, kernel=&quot;linear&quot;, cost=1) Important arguments include type=\"C-classification\" for specifying the task is a classification problem, kernel for specifying the kernel function in SVM, e.g. linear, polynomial and radial (for radial basis kernel), cost for specifying the cost parameter in case of a soft-margin SVM, and any additional parameters used in the kernel function. See the help page for more information. To tune parameters in kernel functions, we could use either tune.svm or tune. cost_range &lt;- ... #specifying the range of parameters tune.svm(Y~., data, type=&quot;C-classification&quot;, kernel=&quot;linear&quot;, cost=cost_range) tune(svm, Y~., data, type=&quot;C-classification&quot;, kernel=&quot;linear&quot;, ranges=list(cost=cost_range)) "],["exercise-1-orange-juice-dataset.html", "2 Exercise 1: Orange juice dataset 2.1 Exploratory data analysis 2.2 Effect of different parameters in SVM 2.3 Build an SVM", " 2 Exercise 1: Orange juice dataset The OJ data from the ISLR package contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. A number of characteristics of the customer and product are recorded. Purchase: A factor with levels CH and MM indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice (i.e. response/class) WeekofPurchase: Week of purchase StoreID: Store ID PriceCH: Price charged for CH PriceMM: Price charged for MM DiscCH: Discount offered for CH DiscMM: Discount offered for MM SpecialCH: Indicator of special on CH SpecialMM: Indicator of special on MM LoyalCH: Customer brand loyalty for CH SalePriceMM:Sale price for MM SalePriceCH: Sale price for CH PriceDiff: Sale price of MM less sale price of CH Store7: A factor with levels No and Yes indicating whether the sale is at Store 7 PctDiscMM: Percentage discount for MM PctDiscCH: Percentage discount for CH ListPriceDiff: List price of MM less list price of CH STORE: Which of 5 possible stores the sale occured at The question of interest is to predict which brand of orange juice a customer will purchase (Purchase variable). Source: Stine, Robert A., Foster, Dean P., Waterman, Richard P. Business Analysis Using Regression (1998). Published by Springer. To load the data, use library(ISLR) data(OJ) 2.1 Exploratory data analysis In R, categorical variables are sometimes recorded as numerical variables, which is inappropriate for subsequent analysis. To address this, as.factor() should be used to convert these variables back into categorical variables. Task Use str, summary and/or skim to inspect the data. Looking at the variable description above, is there any categorical variable encoded incorrectly as numerical variable? If so, correct them by using as.factor(). Excluding the response variable Purchase, how many variables are numerical variables and how many variables are categorical variables? The number of numerical variables = . The number of categorical variables = . Solution library(skimr) str(OJ) ## &#39;data.frame&#39;: 1070 obs. of 18 variables: ## $ Purchase : Factor w/ 2 levels &quot;CH&quot;,&quot;MM&quot;: 1 1 1 2 1 1 1 1 1 1 ... ## $ WeekofPurchase: num 237 239 245 227 228 230 232 234 235 238 ... ## $ StoreID : num 1 1 1 1 7 7 7 7 7 7 ... ## $ PriceCH : num 1.75 1.75 1.86 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ... ## $ PriceMM : num 1.99 1.99 2.09 1.69 1.69 1.99 1.99 1.99 1.99 1.99 ... ## $ DiscCH : num 0 0 0.17 0 0 0 0 0 0 0 ... ## $ DiscMM : num 0 0.3 0 0 0 0 0.4 0.4 0.4 0.4 ... ## $ SpecialCH : num 0 0 0 0 0 0 1 1 0 0 ... ## $ SpecialMM : num 0 1 0 0 0 1 1 0 0 0 ... ## $ LoyalCH : num 0.5 0.6 0.68 0.4 0.957 ... ## $ SalePriceMM : num 1.99 1.69 2.09 1.69 1.69 1.99 1.59 1.59 1.59 1.59 ... ## $ SalePriceCH : num 1.75 1.75 1.69 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ... ## $ PriceDiff : num 0.24 -0.06 0.4 0 0 0.3 -0.1 -0.16 -0.16 -0.16 ... ## $ Store7 : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 2 2 2 2 2 2 ... ## $ PctDiscMM : num 0 0.151 0 0 0 ... ## $ PctDiscCH : num 0 0 0.0914 0 0 ... ## $ ListPriceDiff : num 0.24 0.24 0.23 0 0 0.3 0.3 0.24 0.24 0.24 ... ## $ STORE : num 1 1 1 1 0 0 0 0 0 0 ... skim(OJ) Table 2.1: Data summary Name OJ Number of rows 1070 Number of columns 18 _______________________ Column type frequency: factor 2 numeric 16 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Purchase 0 1 FALSE 2 CH: 653, MM: 417 Store7 0 1 FALSE 2 No: 714, Yes: 356 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist WeekofPurchase 0 1 254.38 15.56 227.00 240.00 257.00 268.00 278.00 ▆▅▅▇▇ StoreID 0 1 3.96 2.31 1.00 2.00 3.00 7.00 7.00 ▇▅▃▁▇ PriceCH 0 1 1.87 0.10 1.69 1.79 1.86 1.99 2.09 ▅▂▇▆▁ PriceMM 0 1 2.09 0.13 1.69 1.99 2.09 2.18 2.29 ▂▁▃▇▆ DiscCH 0 1 0.05 0.12 0.00 0.00 0.00 0.00 0.50 ▇▁▁▁▁ DiscMM 0 1 0.12 0.21 0.00 0.00 0.00 0.23 0.80 ▇▁▂▁▁ SpecialCH 0 1 0.15 0.35 0.00 0.00 0.00 0.00 1.00 ▇▁▁▁▂ SpecialMM 0 1 0.16 0.37 0.00 0.00 0.00 0.00 1.00 ▇▁▁▁▂ LoyalCH 0 1 0.57 0.31 0.00 0.33 0.60 0.85 1.00 ▅▃▆▆▇ SalePriceMM 0 1 1.96 0.25 1.19 1.69 2.09 2.13 2.29 ▁▂▂▂▇ SalePriceCH 0 1 1.82 0.14 1.39 1.75 1.86 1.89 2.09 ▂▁▇▇▅ PriceDiff 0 1 0.15 0.27 -0.67 0.00 0.23 0.32 0.64 ▁▂▃▇▂ PctDiscMM 0 1 0.06 0.10 0.00 0.00 0.00 0.11 0.40 ▇▁▂▁▁ PctDiscCH 0 1 0.03 0.06 0.00 0.00 0.00 0.00 0.25 ▇▁▁▁▁ ListPriceDiff 0 1 0.22 0.11 0.00 0.14 0.24 0.30 0.44 ▂▃▆▇▁ STORE 0 1 1.63 1.43 0.00 0.00 2.00 3.00 4.00 ▇▃▅▅▃ OJ$StoreID &lt;- as.factor(OJ$StoreID) OJ$SpecialCH &lt;- as.factor(OJ$SpecialCH) OJ$SpecialMM &lt;- as.factor(OJ$SpecialMM) OJ$STORE &lt;- as.factor(OJ$STORE) str(OJ) ## &#39;data.frame&#39;: 1070 obs. of 18 variables: ## $ Purchase : Factor w/ 2 levels &quot;CH&quot;,&quot;MM&quot;: 1 1 1 2 1 1 1 1 1 1 ... ## $ WeekofPurchase: num 237 239 245 227 228 230 232 234 235 238 ... ## $ StoreID : Factor w/ 5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 5 5 5 5 5 5 ... ## $ PriceCH : num 1.75 1.75 1.86 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ... ## $ PriceMM : num 1.99 1.99 2.09 1.69 1.69 1.99 1.99 1.99 1.99 1.99 ... ## $ DiscCH : num 0 0 0.17 0 0 0 0 0 0 0 ... ## $ DiscMM : num 0 0.3 0 0 0 0 0.4 0.4 0.4 0.4 ... ## $ SpecialCH : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 2 2 1 1 ... ## $ SpecialMM : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 2 1 1 1 2 2 1 1 1 ... ## $ LoyalCH : num 0.5 0.6 0.68 0.4 0.957 ... ## $ SalePriceMM : num 1.99 1.69 2.09 1.69 1.69 1.99 1.59 1.59 1.59 1.59 ... ## $ SalePriceCH : num 1.75 1.75 1.69 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ... ## $ PriceDiff : num 0.24 -0.06 0.4 0 0 0.3 -0.1 -0.16 -0.16 -0.16 ... ## $ Store7 : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 2 2 2 2 2 2 ... ## $ PctDiscMM : num 0 0.151 0 0 0 ... ## $ PctDiscCH : num 0 0 0.0914 0 0 ... ## $ ListPriceDiff : num 0.24 0.24 0.23 0 0 0.3 0.3 0.24 0.24 0.24 ... ## $ STORE : Factor w/ 5 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 2 2 2 2 1 1 1 1 1 1 ... skim(OJ) Table 2.1: Data summary Name OJ Number of rows 1070 Number of columns 18 _______________________ Column type frequency: factor 6 numeric 12 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Purchase 0 1 FALSE 2 CH: 653, MM: 417 StoreID 0 1 FALSE 5 7: 356, 2: 222, 3: 196, 1: 157 SpecialCH 0 1 FALSE 2 0: 912, 1: 158 SpecialMM 0 1 FALSE 2 0: 897, 1: 173 Store7 0 1 FALSE 2 No: 714, Yes: 356 STORE 0 1 FALSE 5 0: 356, 2: 222, 3: 196, 1: 157 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist WeekofPurchase 0 1 254.38 15.56 227.00 240.00 257.00 268.00 278.00 ▆▅▅▇▇ PriceCH 0 1 1.87 0.10 1.69 1.79 1.86 1.99 2.09 ▅▂▇▆▁ PriceMM 0 1 2.09 0.13 1.69 1.99 2.09 2.18 2.29 ▂▁▃▇▆ DiscCH 0 1 0.05 0.12 0.00 0.00 0.00 0.00 0.50 ▇▁▁▁▁ DiscMM 0 1 0.12 0.21 0.00 0.00 0.00 0.23 0.80 ▇▁▂▁▁ LoyalCH 0 1 0.57 0.31 0.00 0.33 0.60 0.85 1.00 ▅▃▆▆▇ SalePriceMM 0 1 1.96 0.25 1.19 1.69 2.09 2.13 2.29 ▁▂▂▂▇ SalePriceCH 0 1 1.82 0.14 1.39 1.75 1.86 1.89 2.09 ▂▁▇▇▅ PriceDiff 0 1 0.15 0.27 -0.67 0.00 0.23 0.32 0.64 ▁▂▃▇▂ PctDiscMM 0 1 0.06 0.10 0.00 0.00 0.00 0.11 0.40 ▇▁▂▁▁ PctDiscCH 0 1 0.03 0.06 0.00 0.00 0.00 0.00 0.25 ▇▁▁▁▁ ListPriceDiff 0 1 0.22 0.11 0.00 0.14 0.24 0.30 0.44 ▂▃▆▇▁ Use ggplot or ggpairs to visualise numerical variables, answering questions such as which variables may be useful in predicting the type of orange juice purchased by the customer, any outlier/extreme observations. Hint Check Lab 3 Sections 2.1 and 3.2 for examples. Solution Below is an example code examining PriceDiff and ListPriceDiff using density plots and boxplots. library(ggplot2) ggplot(OJ, aes(x=PriceDiff, colour=Purchase)) + geom_density() ggplot(OJ, aes(x=PriceDiff, colour=Purchase)) + geom_boxplot() library(GGally) ggpairs(OJ, columns=c(13,17), ggplot2::aes(colour=Purchase, alpha=0.2)) Produce boxplots of categorical variables separated by groups. Check the helppage of boxplot() or use geom_boxplot() in ggplot. Solution Below is an example code examining SpecialCH using barchart. ggplot(OJ, aes(x=SpecialCH, fill=Purchase)) + geom_bar() 2.2 Effect of different parameters in SVM Before building a powerful SVM classifier, we illustrate the effect of different kernels and/or different parameters in SVM by working with only two numeric variables (hence we could visualise the decision boundary in 2D). Suppose we select PriceDiff and ListPriceDiff. library(e1071) Model_linear &lt;- svm(Purchase~PriceDiff+ListPriceDiff, OJ, type=&quot;C-classification&quot;, kernel=&quot;linear&quot;) plot(Model_linear, OJ, ListPriceDiff~PriceDiff) Model_poly &lt;- svm(Purchase~PriceDiff+ListPriceDiff, OJ, type=&quot;C-classification&quot;, kernel=&quot;poly&quot;, degree=2) plot(Model_poly, OJ, ListPriceDiff~PriceDiff) Model_poly2 &lt;- svm(Purchase~PriceDiff+ListPriceDiff, OJ, type=&quot;C-classification&quot;, kernel=&quot;poly&quot;, degree=5) plot(Model_poly2, OJ, ListPriceDiff~PriceDiff) 2.3 Build an SVM sapply(OJ,is.numeric) ## Purchase WeekofPurchase StoreID PriceCH PriceMM ## FALSE TRUE FALSE TRUE TRUE ## DiscCH DiscMM SpecialCH SpecialMM LoyalCH ## TRUE TRUE FALSE FALSE TRUE ## SalePriceMM SalePriceCH PriceDiff Store7 PctDiscMM ## TRUE TRUE TRUE FALSE TRUE ## PctDiscCH ListPriceDiff STORE ## TRUE TRUE FALSE "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
